{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-13T05:18:47.024752Z",
     "iopub.status.busy": "2021-05-13T05:18:47.013742Z",
     "iopub.status.idle": "2021-05-13T05:19:49.510896Z",
     "shell.execute_reply": "2021-05-13T05:19:49.511987Z"
    },
    "papermill": {
     "duration": 62.517577,
     "end_time": "2021-05-13T05:19:49.512460",
     "exception": false,
     "start_time": "2021-05-13T05:18:46.994883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.15.0)\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Processing /kaggle/input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.18.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2021.2.1)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.5)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.4)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install ../input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from shutil import copyfile\n",
    "copyfile(src = \"../input/k/ragnar123/bert-baseline/tokenization.py\", dst = \"../working/tokenization.py\")\n",
    "import tokenization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T05:19:49.542818Z",
     "iopub.status.busy": "2021-05-13T05:19:49.542322Z",
     "iopub.status.idle": "2021-05-13T05:19:49.546475Z",
     "shell.execute_reply": "2021-05-13T05:19:49.546032Z"
    },
    "papermill": {
     "duration": 0.021753,
     "end_time": "2021-05-13T05:19:49.546587",
     "exception": false,
     "start_time": "2021-05-13T05:19:49.524834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [512, 512]\n",
    "# Seed\n",
    "SEED = 42\n",
    "# Verbosity\n",
    "VERBOSE = 1\n",
    "# Number of classes\n",
    "N_CLASSES = 11014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T05:19:49.739845Z",
     "iopub.status.busy": "2021-05-13T05:19:49.738827Z",
     "iopub.status.idle": "2021-05-13T05:19:54.574664Z",
     "shell.execute_reply": "2021-05-13T05:19:54.574209Z"
    },
    "papermill": {
     "duration": 5.018898,
     "end_time": "2021-05-13T05:19:54.574782",
     "exception": false,
     "start_time": "2021-05-13T05:19:49.555884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will restrict TensorFlow to max 2GB GPU RAM\n",
      "then RAPIDS can use 14GB GPU RAM\n"
     ]
    }
   ],
   "source": [
    "# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n",
    "# SO THAT WE HAVE 14GB RAM FOR RAPIDS\n",
    "LIMIT = 2.0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T05:19:54.615547Z",
     "iopub.status.busy": "2021-05-13T05:19:54.604907Z",
     "iopub.status.idle": "2021-05-13T06:10:30.066757Z",
     "shell.execute_reply": "2021-05-13T06:10:30.066008Z"
    },
    "papermill": {
     "duration": 3035.481895,
     "end_time": "2021-05-13T06:10:30.066910",
     "exception": false,
     "start_time": "2021-05-13T05:19:54.585015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1 embeddings shape is (34250, 1280)\n",
      "B2 embeddings shape is (34250, 1408)\n",
      "B3 embeddings shape is (34250, 1536)\n",
      "B3 embeddings shape is (34250, 2048)\n",
      "Text embeddings shape is (34250, 1024)\n",
      "Text embeddings shape is (34250, 1024)\n",
      "Text embeddings shape is (34250, 1024)\n",
      "Text embeddings shape:  (34250, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "370597"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag to get cv score\n",
    "GET_CV = True\n",
    "# Flag to check ram allocations (debug)\n",
    "CHECK_SUB = False\n",
    "\n",
    "df = cudf.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# If we are comitting, replace train set for test set and dont get cv\n",
    "if len(df) > 3:\n",
    "    GET_CV = False\n",
    "del df\n",
    "\n",
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "# Function to combine predictions\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions'], row['oof_text']])\n",
    "    return ' '.join(np.unique(x))\n",
    "\n",
    "# Function to read out dataset\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, df_cu, image_paths\n",
    "\n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# EfficientNet B1 - Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings_b1(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB1(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../input/shopee-model-image-noisy-student/EfficientNetB1_ep50_512_42-noisy.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'B1 embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "# EfficientNet B2 - Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings_b2(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB2(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../input/shopee-model-image-noisy-student/EfficientNetB2_ep40_512_42-noisy.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'B2 embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "# EfficientNet B3 - Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings_b3(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../input/shopee-model-image-noisy-student/EfficientNetB3_ep30_512_42-noise.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'B3 embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "# EfficientNet B5 - Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings_b5(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB5(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../input/shopee-model-image-noisy-student/EfficientNetB5_ep30_512_42-noisy.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'B3 embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "# Return tokens, masks and segments from a text array or series\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "# Max length = 70, Function to get our text title embeddings using a pre-trained bert model\n",
    "def get_text_embeddings1(df, max_len = 70):\n",
    "    embeds = []\n",
    "    module_url = \"../input/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = 11014, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = margin([clf_output, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
    "    \n",
    "    model.load_weights('../input/shopeemodels/Bert_123_maxlen70_alltrain.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings\n",
    "\n",
    "# Max length = 128, Function to get our text title embeddings using a pre-trained bert model\n",
    "def get_text_embeddings2(df, max_len = 128):\n",
    "    embeds = []\n",
    "    module_url = \"../input/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = 11014, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = margin([clf_output, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
    "    \n",
    "    model.load_weights('../input/shopeemodels/Bert_123_maxlen128-alltrain.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings\n",
    "\n",
    "\n",
    "# Max length = 100, Function to get our text title embeddings using a pre-trained bert model\n",
    "def get_text_embeddings3(df, max_len = 100):\n",
    "    embeds = []\n",
    "    module_url = \"../input/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = 11014, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = margin([clf_output, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
    "    \n",
    "    model.load_weights('../input/shopeemodels/Bert_123_maxlen100-alltrain.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings\n",
    "\n",
    "# Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\n",
    "def get_neighbors(df, embeddings, KNN = 50, image = True):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        if image:\n",
    "            thresholds = list(np.arange(4.0, 12.0, 0.1))\n",
    "        else:\n",
    "            thresholds = list(np.arange(15, 45, 1))\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 6.2)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 27)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "    \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 6.2)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 27)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions\n",
    "    \n",
    "\n",
    "df, df_cu, image_paths = read_dataset()\n",
    "image_embeddings_b1 = get_image_embeddings_b1(image_paths)\n",
    "image_embeddings_b2 = get_image_embeddings_b2(image_paths)\n",
    "image_embeddings_b3 = get_image_embeddings_b3(image_paths)\n",
    "image_embeddings_b5 = get_image_embeddings_b5(image_paths)\n",
    "\n",
    "# Concat the 3 embeddings\n",
    "image_embeddings = np.hstack((np.hstack((np.hstack((image_embeddings_b3, image_embeddings_b2)), image_embeddings_b1)), image_embeddings_b5))\n",
    "# # Average of 3 embeddings\n",
    "# # image_embeddings = np.average([image_embeddings_b3, image_embeddings_b2, image_embeddings_b1], axis = 0)\n",
    "# print(\"Image embeddings shape: \", image_embeddings.shape)\n",
    "\n",
    "text_embeddings1 = get_text_embeddings1(df)\n",
    "text_embeddings2 = get_text_embeddings2(df)\n",
    "text_embeddings3 = get_text_embeddings3(df)\n",
    "\n",
    "# Concat the 3 embeddings\n",
    "text_embeddings = np.hstack((np.hstack((text_embeddings1, text_embeddings2)), text_embeddings3))\n",
    "print(\"Text embeddings shape: \", text_embeddings.shape)\n",
    "del image_embeddings_b1, image_embeddings_b2, image_embeddings_b3, image_embeddings_b5, text_embeddings1, text_embeddings2, text_embeddings3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T06:10:30.102788Z",
     "iopub.status.busy": "2021-05-13T06:10:30.102009Z",
     "iopub.status.idle": "2021-05-13T06:14:39.714650Z",
     "shell.execute_reply": "2021-05-13T06:14:39.715783Z"
    },
    "papermill": {
     "duration": 249.636869,
     "end_time": "2021-05-13T06:14:39.716019",
     "exception": false,
     "start_time": "2021-05-13T06:10:30.079150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 4.0 is 0.6653887638689182\n",
      "Our f1 score for threshold 4.1 is 0.669702149443366\n",
      "Our f1 score for threshold 4.199999999999999 is 0.6742727533118972\n",
      "Our f1 score for threshold 4.299999999999999 is 0.6786594720265349\n",
      "Our f1 score for threshold 4.399999999999999 is 0.6831459649116092\n",
      "Our f1 score for threshold 4.499999999999998 is 0.6877829465471498\n",
      "Our f1 score for threshold 4.599999999999998 is 0.6925912673316873\n",
      "Our f1 score for threshold 4.6999999999999975 is 0.6972424855675161\n",
      "Our f1 score for threshold 4.799999999999997 is 0.7028380920946983\n",
      "Our f1 score for threshold 4.899999999999997 is 0.7083067532633526\n",
      "Our f1 score for threshold 4.9999999999999964 is 0.7146553440627591\n",
      "Our f1 score for threshold 5.099999999999996 is 0.7204329439326065\n",
      "Our f1 score for threshold 5.199999999999996 is 0.7274526175164933\n",
      "Our f1 score for threshold 5.299999999999995 is 0.7347787919495777\n",
      "Our f1 score for threshold 5.399999999999995 is 0.7422290893299613\n",
      "Our f1 score for threshold 5.499999999999995 is 0.7500868711729626\n",
      "Our f1 score for threshold 5.599999999999994 is 0.7584552785554664\n",
      "Our f1 score for threshold 5.699999999999994 is 0.7674037466274714\n",
      "Our f1 score for threshold 5.799999999999994 is 0.7763088693497008\n",
      "Our f1 score for threshold 5.899999999999993 is 0.7860374199702195\n",
      "Our f1 score for threshold 5.999999999999993 is 0.7954093816166996\n",
      "Our f1 score for threshold 6.0999999999999925 is 0.8050394833490733\n",
      "Our f1 score for threshold 6.199999999999992 is 0.8155837538822455\n",
      "Our f1 score for threshold 6.299999999999992 is 0.8250604560417703\n",
      "Our f1 score for threshold 6.3999999999999915 is 0.8361011281865804\n",
      "Our f1 score for threshold 6.499999999999991 is 0.8459207143252642\n",
      "Our f1 score for threshold 6.599999999999991 is 0.85608163254193\n",
      "Our f1 score for threshold 6.69999999999999 is 0.8652588281836707\n",
      "Our f1 score for threshold 6.79999999999999 is 0.874504521684034\n",
      "Our f1 score for threshold 6.89999999999999 is 0.8824419949959936\n",
      "Our f1 score for threshold 6.999999999999989 is 0.8905870682525072\n",
      "Our f1 score for threshold 7.099999999999989 is 0.8984869735444485\n",
      "Our f1 score for threshold 7.199999999999989 is 0.9051649691918618\n",
      "Our f1 score for threshold 7.299999999999988 is 0.9113359206046304\n",
      "Our f1 score for threshold 7.399999999999988 is 0.9162253897544604\n",
      "Our f1 score for threshold 7.499999999999988 is 0.9210509234629416\n",
      "Our f1 score for threshold 7.599999999999987 is 0.923496106337823\n",
      "Our f1 score for threshold 7.699999999999987 is 0.925571370259408\n",
      "Our f1 score for threshold 7.7999999999999865 is 0.9252539063721161\n",
      "Our f1 score for threshold 7.899999999999986 is 0.9233683607410654\n",
      "Our f1 score for threshold 7.999999999999986 is 0.9184137374565041\n",
      "Our f1 score for threshold 8.099999999999985 is 0.9116724148113393\n",
      "Our f1 score for threshold 8.199999999999985 is 0.9018248221089529\n",
      "Our f1 score for threshold 8.299999999999985 is 0.8878713569526712\n",
      "Our f1 score for threshold 8.399999999999984 is 0.8686315953413232\n",
      "Our f1 score for threshold 8.499999999999984 is 0.844240987452094\n",
      "Our f1 score for threshold 8.599999999999984 is 0.814809994167599\n",
      "Our f1 score for threshold 8.699999999999983 is 0.7784136327843074\n",
      "Our f1 score for threshold 8.799999999999983 is 0.7389989817332939\n",
      "Our f1 score for threshold 8.899999999999983 is 0.6957102354864662\n",
      "Our f1 score for threshold 8.999999999999982 is 0.6513333792631412\n",
      "Our f1 score for threshold 9.099999999999982 is 0.605554933151154\n",
      "Our f1 score for threshold 9.199999999999982 is 0.5607146424543703\n",
      "Our f1 score for threshold 9.299999999999981 is 0.516717282298564\n",
      "Our f1 score for threshold 9.39999999999998 is 0.4754862231828014\n",
      "Our f1 score for threshold 9.49999999999998 is 0.4370085884606655\n",
      "Our f1 score for threshold 9.59999999999998 is 0.4016801899851349\n",
      "Our f1 score for threshold 9.69999999999998 is 0.3700108941947739\n",
      "Our f1 score for threshold 9.79999999999998 is 0.3411069283642896\n",
      "Our f1 score for threshold 9.899999999999979 is 0.3161775957698909\n",
      "Our f1 score for threshold 9.999999999999979 is 0.2941532447654657\n",
      "Our f1 score for threshold 10.099999999999978 is 0.27494967628521416\n",
      "Our f1 score for threshold 10.199999999999978 is 0.25794103204536395\n",
      "Our f1 score for threshold 10.299999999999978 is 0.2431788603212614\n",
      "Our f1 score for threshold 10.399999999999977 is 0.2299846823875508\n",
      "Our f1 score for threshold 10.499999999999977 is 0.21844385148056034\n",
      "Our f1 score for threshold 10.599999999999977 is 0.20806184758025306\n",
      "Our f1 score for threshold 10.699999999999976 is 0.19873832673957162\n",
      "Our f1 score for threshold 10.799999999999976 is 0.19046365438038887\n",
      "Our f1 score for threshold 10.899999999999975 is 0.18308044928853656\n",
      "Our f1 score for threshold 10.999999999999975 is 0.17644252131568613\n",
      "Our f1 score for threshold 11.099999999999975 is 0.17056976590799675\n",
      "Our f1 score for threshold 11.199999999999974 is 0.16529838451145565\n",
      "Our f1 score for threshold 11.299999999999974 is 0.16061501955053048\n",
      "Our f1 score for threshold 11.399999999999974 is 0.1563500694436157\n",
      "Our f1 score for threshold 11.499999999999973 is 0.15254814875792075\n",
      "Our f1 score for threshold 11.599999999999973 is 0.14911485484696085\n",
      "Our f1 score for threshold 11.699999999999973 is 0.14599180683865084\n",
      "Our f1 score for threshold 11.799999999999972 is 0.14322365721110453\n",
      "Our f1 score for threshold 11.899999999999972 is 0.14056730794401104\n",
      "Our best score is 0.925571370259408 and has a threshold 7.699999999999987\n"
     ]
    }
   ],
   "source": [
    "# Get neighbors for image_embeddings\n",
    "df, image_predictions = get_neighbors(df, image_embeddings, KNN = 100, image = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T06:14:39.833172Z",
     "iopub.status.busy": "2021-05-13T06:14:39.832364Z",
     "iopub.status.idle": "2021-05-13T06:16:04.996509Z",
     "shell.execute_reply": "2021-05-13T06:16:04.995994Z"
    },
    "papermill": {
     "duration": 85.225507,
     "end_time": "2021-05-13T06:16:04.996652",
     "exception": false,
     "start_time": "2021-05-13T06:14:39.771145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 15 is 0.5262609187869624\n",
      "Our f1 score for threshold 16 is 0.539862697625738\n",
      "Our f1 score for threshold 17 is 0.5561106338127454\n",
      "Our f1 score for threshold 18 is 0.5760145531940132\n",
      "Our f1 score for threshold 19 is 0.6002910806240738\n",
      "Our f1 score for threshold 20 is 0.627853826793871\n",
      "Our f1 score for threshold 21 is 0.6600771857213912\n",
      "Our f1 score for threshold 22 is 0.6951975489093759\n",
      "Our f1 score for threshold 23 is 0.7317189113943475\n",
      "Our f1 score for threshold 24 is 0.7687843701630244\n",
      "Our f1 score for threshold 25 is 0.8030330369381454\n",
      "Our f1 score for threshold 26 is 0.8359888091161103\n",
      "Our f1 score for threshold 27 is 0.8655600110588879\n",
      "Our f1 score for threshold 28 is 0.8913244336214908\n",
      "Our f1 score for threshold 29 is 0.9145462228419219\n",
      "Our f1 score for threshold 30 is 0.9337629198949475\n",
      "Our f1 score for threshold 31 is 0.9491939391606589\n",
      "Our f1 score for threshold 32 is 0.9625831418564712\n",
      "Our f1 score for threshold 33 is 0.9733825997850317\n",
      "Our f1 score for threshold 34 is 0.9811898314997298\n",
      "Our f1 score for threshold 35 is 0.9863276382140383\n",
      "Our f1 score for threshold 36 is 0.9896042077015441\n",
      "Our f1 score for threshold 37 is 0.9913020330690138\n",
      "Our f1 score for threshold 38 is 0.9921977386142031\n",
      "Our f1 score for threshold 39 is 0.9927824319331185\n",
      "Our f1 score for threshold 40 is 0.9929551674512643\n",
      "Our f1 score for threshold 41 is 0.9929064238152647\n",
      "Our f1 score for threshold 42 is 0.9927175636531154\n",
      "Our f1 score for threshold 43 is 0.9922467834932737\n",
      "Our f1 score for threshold 44 is 0.9906381075900895\n",
      "Our best score is 0.9929551674512643 and has a threshold 40\n"
     ]
    }
   ],
   "source": [
    "# Get neighbors for text_embeddings\n",
    "df, text_predictions = get_neighbors(df, text_embeddings, KNN = 100, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T06:16:05.086716Z",
     "iopub.status.busy": "2021-05-13T06:16:05.086130Z",
     "iopub.status.idle": "2021-05-13T06:16:21.585407Z",
     "shell.execute_reply": "2021-05-13T06:16:21.584783Z"
    },
    "papermill": {
     "duration": 16.548832,
     "end_time": "2021-05-13T06:16:21.585576",
     "exception": false,
     "start_time": "2021-05-13T06:16:05.036744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/cudf/core/join/join.py:368: UserWarning: can't safely cast column from right with type int32 to uint16, upcasting to int32\n",
      "  \"right\", dtype_r, dtype_l, libcudf_join_type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text embeddings shape (34250, 25000)\n"
     ]
    }
   ],
   "source": [
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "model = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\n",
    "text_embeddings2 = model.fit_transform(df_cu.title).toarray()\n",
    "print('text embeddings shape',text_embeddings2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T06:16:21.675392Z",
     "iopub.status.busy": "2021-05-13T06:16:21.672997Z",
     "iopub.status.idle": "2021-05-13T06:18:42.970341Z",
     "shell.execute_reply": "2021-05-13T06:18:42.969310Z"
    },
    "papermill": {
     "duration": 141.34357,
     "end_time": "2021-05-13T06:18:42.970488",
     "exception": false,
     "start_time": "2021-05-13T06:16:21.626918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar titles...\n",
      "chunk 0 to 4096\n",
      "chunk 4096 to 8192\n",
      "chunk 8192 to 12288\n",
      "chunk 12288 to 16384\n",
      "chunk 16384 to 20480\n",
      "chunk 20480 to 24576\n",
      "chunk 24576 to 28672\n",
      "chunk 28672 to 32768\n",
      "chunk 32768 to 34250\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "print('Finding similar titles...')\n",
    "CTS = len(df_cu)//CHUNK\n",
    "if len(df_cu)%CHUNK!=0: CTS += 1\n",
    "for j in range( CTS ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(df_cu))\n",
    "    print('chunk',a,'to',b)\n",
    "    \n",
    "    # COSINE SIMILARITY DISTANCE\n",
    "    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n",
    "    cts = cupy.matmul(text_embeddings2, text_embeddings2[a:b].T).T\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        # IDX = np.where(cts[k,]>0.7)[0]\n",
    "        IDX = cupy.where(cts[k,]>0.75)[0]\n",
    "        o = df_cu.iloc[cupy.asnumpy(IDX)].posting_id.to_pandas().values\n",
    "        preds.append(o)\n",
    "        \n",
    "del model, text_embeddings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T06:18:43.088342Z",
     "iopub.status.busy": "2021-05-13T06:18:43.087590Z",
     "iopub.status.idle": "2021-05-13T06:18:43.094470Z",
     "shell.execute_reply": "2021-05-13T06:18:43.094853Z"
    },
    "papermill": {
     "duration": 0.081449,
     "end_time": "2021-05-13T06:18:43.094998",
     "exception": false,
     "start_time": "2021-05-13T06:18:43.013549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cu['oof_text'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T06:18:43.193778Z",
     "iopub.status.busy": "2021-05-13T06:18:43.190246Z",
     "iopub.status.idle": "2021-05-13T06:18:45.040704Z",
     "shell.execute_reply": "2021-05-13T06:18:45.039775Z"
    },
    "papermill": {
     "duration": 1.903239,
     "end_time": "2021-05-13T06:18:45.040839",
     "exception": false,
     "start_time": "2021-05-13T06:18:43.137600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final f1 cv score is 0.9226756987285178\n"
     ]
    }
   ],
   "source": [
    "# Concatenate image predctions with text predictions\n",
    "if GET_CV:\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['text_predictions'] = text_predictions\n",
    "    df['oof_text'] = df_cu['oof_text'].to_pandas().values\n",
    "    df['pred_matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "    score = df['f1'].mean()\n",
    "    print(f'Our final f1 cv score is {score}')\n",
    "    df['matches'] = df['pred_matches']\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['oof_text'] = df_cu['oof_text'].to_pandas().values\n",
    "    df['text_predictions'] = text_predictions\n",
    "    df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3605.32973,
   "end_time": "2021-05-13T06:18:47.399466",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-13T05:18:42.069736",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
